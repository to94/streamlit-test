# -*- coding: utf-8 -*-
"""영화추천시스템.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/147oPEqMfjlFE2UzznjrW4-SI8Pu6zVDX

### 영화 추천 시스템
1. Deomographic Filtering(인구통계학적 필터링)
  - 많은 사람들이 일반적으로 좋아하는 장르 추천
  - 누가봐도 좋아할만한
2. Content Based Filtering(컨텐츠 기반 필터링)
  - 특정 아이템에 기반한 유사 아이템
  - 장르나 배우 등 비슷한 것 추천
3. Collaborative Filtering(협업 필터링)
  - 비슷한 영화 취향을 가진 사람들 매칭시켜서 추천
"""

from google.colab import drive
drive.mount('/content/drive')

# Deomographic Filtering(인구통계학적 필터링)
import pandas as pd
import numpy as np

df1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/파이썬 무료 강의(인공지능/tmdb_5000_credits.csv')
df2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/파이썬 무료 강의(인공지능/tmdb_5000_movies.csv')

df1.head()

df2.head()

df1.shape, df2.shape

# 데이터프레임간의 컬럼 데이터 비교
df1.title.equals(df2['title'])

df1.columns = ['id', 'title', 'cast', 'crew']
df1[['id', 'cast', 'crew']]

df2 = df2.merge(df1[['id', 'cast', 'crew']], on='id')
df2.head()

"""영화 1 : 영화의 평점 10/10 -> 5명 평가
영화 2 : 영화의 평점 8/10 -> 500명 평가

>영화 2 의 신뢰도가 더 높다
"""

# 평점 가중치 식 만들기

C = df2.vote_average.mean()
C

m = df2.vote_count.quantile(0.9)  # quantile() -> 분위수 값 출력, 상위 10퍼퍼
m

q_movies = df2.copy().loc[df2['vote_count']>m]
q_movies.shape

q_movies['vote_count'].sort_values()

def weight_rating(x, m=m, C=C):
  v = x['vote_count']
  R = x['vote_average']
  return (v/ (v+m) * R) + (m / (m+v) * C)

q_movies['score'] = q_movies.apply(weight_rating, axis=1)

q_movies

q_movies = q_movies.sort_values('score', ascending=False)
q_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)

pop= df2.sort_values('popularity', ascending=False)
import matplotlib.pyplot as plt
plt.figure(figsize=(12,4))

plt.barh(pop['title'].head(10),pop['popularity'].head(10), align='center', 
        color='skyblue') # align -> xtick 위치, 
plt.gca().invert_yaxis()
plt.xlabel("Popularity")
plt.title("Popular Movies")

"""## 2. Content Based Filtering(컨텐츠 기반 필터링)
### 줄거리 기반
"""

## 2. Content Based Filtering(컨텐츠 기반 필터링)
df2['overview'].head()

"""### Bag of Words - Bow

I am a boy

I am a girl

### 피처벡터화
단어가 나온 횟수
I<2>, am<2>, a<2>, boy<1>, girl<1>
            I    am    a     boy    girl
문장 1  1      1      1      1        0     (1, 1, 1, 1, 0)
문장 2  1      1      1      0        1     (1, 1, 1, 0, 1)

문서 100개
모든 문서에서 나온 단어 10,000개
100 * 10,000 = 100만

###방법
1. TFidVectorizer ( TK-IDF 기반의 벡터화) - a, the 등 크게 중요치 않은 내용은 걸러내는것
2. CountVectorizer - (단어 전부 세줌)
"""

# Bag of Words - Bow
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words = 'english') # the, a 같이 큰 의미 없는 단어 제거

# 제거되는 단어 항목
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
ENGLISH_STOP_WORDS

# NULL 값이 있는지 확인
df2['overview'].isnull().values.any()

df2['overview'].isnull().sum()

df2['overview'] = df2['overview'].fillna('')

# 피처벡터화
tfidf_matrix = tfidf.fit_transform(df2['overview'])
tfidf_matrix.shape

# 4803개의 문장 -> 20978개의 단어로 이루어져있다는 뜻
tfidf_matrix

# 코사인유사도 구하기
# 1. cosine_similarity
# 2. linear_kernel - 좀더 빠름
from sklearn.metrics.pairwise import linear_kernel
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
cosine_sim

cosine_sim.shape

indices = pd.Series(df2.index, index=df2['title']).drop_duplicates() # drop_duplicates() -> 중복 행 제거, https://wikidocs.net/154060
indices

indices['The Dark Knight Rises']

# 영화의 제목을 입력받으면 코사인 유사도를 통해 가장 유사도가 높은 상위 영화 10개 반환
def get_recommendations(title, cosine_sim=cosine_sim):
  idx = indices[title]

  # 코사인 유사도 매트릭스에서 idx에 해당하는 데이터를 (idx, 유사도) 형태로 얻기
  sim_scores = list(enumerate(cosine_sim[idx]))

  # 코사인 유사도 기준으로 내림차순 정렬
  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
  
  # 자기자신을 제외한 영화 10개 추천받기
  sim_scores = sim_scores[1:11]

  # 추천 영화 목록 10개의 인덱스 정보 추출
  movie_indices = [i[0] for i in sim_scores]

  # 인덱스 정보를 통해 영화 제목 추출
  return df2['title'].iloc[movie_indices]

# 과정
# 타이틀을 넣으면 인덱스 받아오기
test_idx = indices['The Dark Knight Rises'] # 영화 제목을 통해서 전체 데이터 기준 그 영화의 index 값 얻기
test_idx

# 인덱스에서 해당 영화의 정보 얻어오기
# 코사인 유사도 매트릭스에서 idx에 해당하는 데이터를 (idx, 유사도) 형태로 얻기기
test_sim_scores = list(enumerate(cosine_sim[3]))
test_sim_scores1 = list(enumerate(cosine_sim[3]))

# sorted -> 원본데이터는 건드리지 않는다다
test_sim_scores = sorted(test_sim_scores, key=lambda x: x[1], reverse=True)
test_sim_scores[1:11]

# 추천영화목록 10개의 인덱스 정보 추출
test_movie_indices = [i[0] for i in test_sim_scores[1:11]]
test_movie_indices

# 인덱스 값을 통해 영화제목 가져오기
df2['title'].iloc[test_movie_indices]

df2['title'].iloc[3]

# 실행
df2['title'][:20]

get_recommendations('Avengers: Age of Ultron')

get_recommendations('The Martian')

"""### 다양한 요소 기반 추천"""

df2.head(3)

type(df2.loc[0, 'genres']), df2.loc[0, 'genres']

s1 = [{"id": 28, "name": "Action"}]
s2 = '[{"id": 28, "name": "Action"}]'

type(s1), type(s2)

# 문자열 -> 리스트 변경경
from ast import literal_eval
s2 = literal_eval(s2)
s2, type(s2)

print(type(s1), type(s2))

# 문자열로 된 데이터 리스트로 변경
features = ['cast', 'crew', 'keywords', 'genres']
for feature in features:
  df2[feature] = df2[feature].apply(literal_eval)

df2.loc[0, 'crew']

# 감독 정보만 가져오기
def get_director(x):
  for i in x:
    if i['job'] == 'Director' :
      return i['name']
  return np.nan

df2['director'] = df2['crew'].apply(get_director)
df2['director']

df2[df2['director'].isnull()]

# cast
df2.loc[0, 'cast']

df2.loc[0, 'genres']

df2.loc[0, 'keywords']

# 처음 3개의 데이터 중에서 name 에 해당하는 value만 추출
def get_list(x):
  if isinstance(x, list):
    names = [i['name'] for i in x]
    if len(names) > 3:
      names = names[:3]
    return names
  return []

features = ['cast', 'keywords', 'genres']
for feature in features:
  df2[feature] = df2[feature].apply(get_list)

df2[['title', 'cast','director','keywords','genres']].head(3)

# 벡터화를 위한 공백제거 및 소문자화
# 이름 같은 경우 띄어쓰기가 있으면 같은 한사람이 두명으로 분리되어 계산되기에 띄어쓰기 제거
def clean_data(x):
  if isinstance(x, list):
    return [str.lower(i.replace(' ', '')) for i in x]
  else:
    if isinstance(x, str):
      return str.lower(x.replace(' ', ''))
    else:
      return ''

features = ['cast', 'keywords', 'director', 'genres']
for feature in features:
  df2[feature] = df2[feature].apply(clean_data)

df2[['cast', 'keywords', 'director', 'genres']].head(3)

# 키워드, 캐스트, 디렉터, 장르 하나의 문장으로 만들어주기

def create_soup(x):
    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])
df2['soup'] = df2.apply(create_soup, axis=1)
df2['soup']

from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words = 'english')
count_matrix = count.fit_transform(df2['soup'])
count_matrix

from sklearn.metrics.pairwise import cosine_similarity
cosine_sim2 = cosine_similarity(count_matrix, count_matrix)
cosine_sim2

indices['Avatar']

df2 = df2.reset_index()
indices = pd.Series(df2.index, index=df2['title'])
indices

get_recommendations('The Dark Knight Rises', cosine_sim2)

get_recommendations('Up', cosine_sim2)

get_recommendations('The Martian', cosine_sim2)

df2.loc[270]

df2.loc[4]

# 파일로 만들기
import pickle

movies = df2[['id', 'title']].copy()
movies.head(5)

pickle.dump(movies, open('movies.pickle', 'wb'))

pickle.dump(cosine_sim2, open('cosine_sim.pickle', 'wb'))

